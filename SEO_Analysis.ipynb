{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsr9llgi0E3V8gpVX7iFHc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpksomvanshi/web_scrapping/blob/main/SEO_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8qP8psRmwZma"
      },
      "outputs": [],
      "source": [
        "## warning, Title Tag, Meta Description, Image ALT Tags, Keywords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt8FeZbZwwvp",
        "outputId": "77d83bc9-34a2-43dc-b8ff-a63da75d61ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SEO_Analysis(url):\n",
        "  ## send get request to get the website\n",
        "  response = requests.get(url)\n",
        "  ## Check the response code status\n",
        "  if response.status_code != 200:\n",
        "    print('Error! Unable to access the website')\n",
        "    return\n",
        "\n",
        "## save the good and bad as warnings in the list\n",
        "url =\"https://pythonology.eu/what-is-syntax-in-programming-and-linguistics/\"\n",
        "response = requests.get(url)\n",
        "SEO_Analysis(url)\n",
        "\n",
        "good = []\n",
        "bad = []\n",
        "## parse the HTML content\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Extract the title and description\n",
        "title = soup.find('title').get_text()\n",
        "description = soup.find('meta', attrs={'name': 'description'})['content']\n",
        "\n",
        "\n",
        "# Check if the title and description exist\n",
        "if title:\n",
        "  good.append(f\"Great,Title Exists! Meta Title of this page is: {title}\")\n",
        "else:\n",
        "    bad.append(\"Title does not exist! Add a Title\")\n",
        "\n",
        "if description:\n",
        "  good.append(f\"Great, Description Exists! Meta Description of this web page is: {description}\")\n",
        "else:\n",
        "  bad.append(\"Description does not exist! Add a Meta Description\")\n",
        "\n",
        "# Grab the Headings\n",
        "hs = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']\n",
        "h_tags = []\n",
        "\n",
        "for h in soup.find_all(hs):\n",
        "  good.append(f\"{h.name}-->{h.text.strip()}\")\n",
        "  h_tags.append(h.name)\n",
        "\n",
        "if 'h1' not in h_tags:\n",
        "  bad.append(\"No H1 found!\")\n",
        "\n",
        "# Extract the images without Alt\n",
        "for i in soup.find_all('img', alt=''):\n",
        "  bad.append(f\"No Alt: {i}\")\n",
        "\n",
        "# Extract keywords\n",
        "# Grab the text from the body of html\n",
        "bod = soup.find('body').text\n",
        "  bod\n",
        "\n",
        "# Extract all the words in the body and lowercase them in a list\n",
        "words = [i.lower() for i in word_tokenize(bod)]\n",
        "\n",
        "# Grab a list of English stopwords\n",
        "sw = nltk.corpus.stopwords.words('english')\n",
        "new_words = []\n",
        "\n",
        "# Put the tokens which are not stopwords and are actual words (no punctuation) in a new list\n",
        "for i in words:\n",
        "  if i not in sw and i.isalpha():\n",
        "    new_words.append(i)\n",
        "\n",
        "# Extract the fequency of the words and get the 10 most common ones\n",
        "freq = nltk.FreqDist(new_words)\n",
        "keywords= freq.most_common(10)\n",
        "\n",
        "# Print the results\n",
        "print(\"Keywords: \\n\", keywords)\n",
        "print(\"The Good: \\n\", good)\n",
        "print(\"The Bad: \", bad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3S2TRYOyn_b",
        "outputId": "58bbdd58-ad10-4cec-d10c-b160edb2d3c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keywords: \n",
            " [('syntax', 24), ('language', 17), ('linguistics', 16), ('sentence', 11), ('programming', 10), ('nlp', 10), ('study', 8), ('structure', 8), ('words', 8), ('python', 6)]\n",
            "The Good: \n",
            " ['Great,Title Exists! Meta Title of this page is: What is Syntax in Programming and Linguistics? | pythonology', 'Great, Description Exists! Meta Description of this web page is: If you come from a programming background, you have heard the word syntax a lot: the Syntax of Python, Java,... As a Linguist (Ph.D. in Linguistics), I DO NOT get asked this question enough by programmers! Apparently, everyone knows what it is. So, why bother writing about it? Syntax is one of the most important', 'h1-->What is Syntax in Programming and Linguistics?', 'h2-->What is Linguistics?', 'h2-->What is syntax?', 'h3-->Syntactic Tree Diagram', 'h2-->Syntax and Chomsky', 'h2-->What is syntax in programming?', 'h2-->Post navigation', 'h2-->Similar Posts', 'h3-->NLP with Stanza: Guide to an NLP package for many languages', 'h3-->Apply NLP to Genre Analysis of Abstract Sections in Research Articles Across Hard Sciences', 'h2-->More Python...']\n",
            "The Bad:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3i3Y0Z5M0ymY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}